import argparse     # Terminal Ã¼zerinden parametre almayÄ± saÄŸlar (ex: --message)
import logging      # Program Ã§alÄ±ÅŸÄ±rken bilgi veya hata mesajlarÄ±nÄ± loglamak iÃ§in
from typing import Annotated    # State tanÄ±mÄ±nda veri tÃ¼rlerini belirtmek iÃ§in (type hinting)
from typing_extensions import TypedDict
from langchain.chat_models import init_chat_model   # LLMâ€™i baÅŸlatmak iÃ§in LangChain arayÃ¼zÃ¼
from langgraph.graph import StateGraph, START, END  # LangGraphâ€™in Ã§ekirdeÄŸi: graph yapÄ±sÄ±nÄ± yÃ¶netir
from langgraph.graph.message import add_messages    # LangGraphâ€™in â€œmesajlarÄ± biriktirâ€ (append) Ã¶zelliÄŸi
from dotenv import load_dotenv
import os

load_dotenv()

print("----- 01_basic_chatbot/main.py -----")

# Setup logging
# Bu iki satÄ±r, loglama sistemini kurar.
# Program boyunca â€œinfoâ€, â€œerrorâ€, â€œdebugâ€ gibi mesajlarÄ± terminalde gÃ¶rebilmeni saÄŸlar.
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Define the state of our chatbot (Official LangGraph Pattern)
# LangGraph, bir state machine (durum makinesi) mantÄ±ÄŸÄ±nda Ã§alÄ±ÅŸÄ±r.
# Yani grafÄ±n her adÄ±mÄ±nda taÅŸÄ±nan â€œveriâ€ bir State iÃ§inde tutulur.
# Bu State bir Python sÃ¶zlÃ¼ÄŸÃ¼ gibidir (dict), 
# ama tip gÃ¼venliÄŸi iÃ§in TypedDict ile tanÄ±mlanmÄ±ÅŸtÄ±r.
class State(TypedDict):
    """
    Represents the state of our chatbot.
    
    The `messages` key contains the conversation history.
    The `add_messages` annotation tells LangGraph to append new messages
    to the list instead of overwriting the entire list.
    """
    messages: Annotated[list, add_messages]

# Initialize LLM
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise ValueError("GOOGLE_API_KEY not found in environment variables")

llm = init_chat_model("gemini-2.5-flash", model_provider="google_genai", api_key=api_key)

def chatbot(state: State):
    """
    The main chatbot node function.
    
    This function:
    1. Takes the current state as input (yani geÃ§miÅŸ konuÅŸmalar)
    2. Invokes the LLM with the conversation messages
    3. Returns the updated state with the LLM's response
    
    Args:
        state: Current conversation state containing messages
        
    Returns:
        dict: Updated state with new message from LLM
    """
    # Get the LLM's response to the conversation
    response = llm.invoke(state["messages"])
    
    # Return the response in the format expected by our state
    return {"messages": [response]}

# Build the graph following official LangGraph tutorial
def build_chatbot_graph():
    """
    Creates the basic chatbot graph with official LangGraph pattern.
    
    Graph structure:
    START -> chatbot -> END
    
    Returns:
        Compiled LangGraph that can process conversations
    """
    # Create a StateGraph with our State schema
    graph_builder = StateGraph(State)
    
    # Add the chatbot node
    graph_builder.add_node("chatbot", chatbot) # â†’ â€œchatbotâ€ isminde bir node eklenir ve bu node chatbot() fonksiyonunu Ã§alÄ±ÅŸtÄ±rÄ±r.
    
    # Define the flow: START -> chatbot -> END
    graph_builder.add_edge(START, "chatbot")
    graph_builder.add_edge("chatbot", END)
    
    # Compile the graph
    return graph_builder.compile()  # â†’ Graph artÄ±k Ã§alÄ±ÅŸtÄ±rÄ±labilir hale gelir (LangGraph bunu optimize edip dondurur).

def main():
    # argparse.ArgumentParser: Terminalden parametre almayÄ± saÄŸlar.
    # --message: kullanÄ±cÄ±dan gelen metni temsil eder.
    # required=True: bu parametre zorunludur; verilmezse hata alÄ±rsÄ±n.
    parser = argparse.ArgumentParser(description="Basic Chatbot - Official LangGraph Tutorial")
    parser.add_argument("--message", type=str, required=True,
                        help="Message to send to the chatbot")
    
    args = parser.parse_args()
    
    print("\n" + "="*80)
    print("BASIC CHATBOT - OFFICIAL LANGGRAPH TUTORIAL")
    print("="*80)
    print("Building a basic chatbot using LangGraph StateGraph...")
    print("="*80)
    
    try:
        # Build the chatbot graph
        graph = build_chatbot_graph()
        
        # Create the initial state with user message
        from langchain_core.messages import HumanMessage
        initial_state = {
            "messages": [HumanMessage(content=args.message)]
        }
        
        # KullanÄ±cÄ± MesajÄ±nÄ± YazdÄ±rma
        print(f"\n -User: {args.message}")
        print("-" * 50)
        
        # Run the chatbot
        logger.info("Processing message through chatbot graph...")
        
        # ğŸš€ğŸš€ğŸš€ Invoke the graph with our initial state
        result = graph.invoke(initial_state)
        # 1. graph.invoke() â†’ LangGraphâ€™in derlenmiÅŸ grafÄ±nÄ± baÅŸlatÄ±r.
        # 2. initial_state  â†’ giriÅŸ olarak verilen state, grafÄ±n START noktasÄ±na iletilir.
        # 3. AkÄ±ÅŸ ÅŸu ÅŸekilde ilerler: START â†’ chatbot(state) â†’ END
        # 4. chatbot() nodeâ€™u LLMâ€™i Ã§aÄŸÄ±rÄ±r (llm.invoke(state["messages"]))
        # 5. CevabÄ± dÃ¶ndÃ¼rÃ¼r ve LangGraph stateâ€™i gÃ¼nceller.
        # result adlÄ± deÄŸiÅŸkende konuÅŸmanÄ±n tamamÄ± tutulur: Ã¶rn:
        # {
        #     "messages": [
        #         HumanMessage(content="Hello!"),
        #         AIMessage(content="Hi there! How can I help you?")
        #     ]
        # }

        
        # Extract the chatbot's response (last message in the conversation)
        chatbot_response = result["messages"][-1].content   # son mesajÄ± alÄ±r (LLMâ€™den gelen cevap)
        
        print(f"Chatbot: {chatbot_response}")
        
        print("\n" + "="*80)
        print("Basic chatbot conversation complete!")
        print("="*80)
        
        # Show the complete conversation state
        print("\n Complete Conversation State:")
        print("-" * 40)
        
        # Iterate through all messages in the conversation history
        for i, msg in enumerate(result["messages"], 1):
            # Determine the role based on message type (human/user vs assistant/chatbot)
            if hasattr(msg, 'type'):
                # msg.type kullanarak kimin konuÅŸtuÄŸunu belirler
                role = "User" if msg.type == "human" else "Chatbot" 
            else:
                role = "Chatbot"

            # Extract message content safely and truncate to first 100 characters for display
            content = getattr(msg, 'content', str(msg))
            print(f"{i}. {role}: {content[:100]}...")
        
        logger.info("Chatbot session completed successfully... \n")
        
    except Exception as e:
        logger.error(f"Error in chatbot: {e}")
        print(f"Error: {e}")

if __name__ == "__main__":
    main()